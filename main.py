import streamlit as st  # type: ignore
import pdfplumber  # type: ignore
import re
from collections import Counter
import os
import io

st.set_page_config(page_title="OkuLM", layout="wide")
st.title("OkuLM ‚Äî –û–∫—É—É —Ç–∞–ª–¥–æ–æ—Å—É")

K_STOP = {
    '–º–µ–Ω', '—Å–µ–Ω', '–∞–ª', '–±–æ–ª—É–ø', '–±–∞—Ä', '–∂–∞–Ω–∞', '–º–µ–Ω–∏–Ω', '—Å–µ–Ω–∏–Ω', '–∞–ª–∞—Ä', '“Ø—à“Ø–Ω', '“Ø—á“Ø–Ω',
    '–∂–µ', '–±—É–ª', '–±–∏—Ä', '—ç–º–µ—Å', '–¥–∞', '–∞–Ω—ã', '–º–µ–Ω–µ', '”©–∑', '–∫”©–ø', '–∞–∑', '—Å”©–∑', '–∞–π—Ç', '–±–æ–ª',
    '—ç–º–∏', '–∫–∞–π—Å—ã', '–∫–∞–Ω—á–∞', '–∫–∞–π–¥–∞', '–∫–∞–Ω—Ç–∏–ø', '–∞–Ω–∞–Ω', 'ÔøΩÔøΩ–Ω—ã–Ω', '–±–∞—Ä–¥—ã–∫'
}

SENT_RE = re.compile(r'(?<=[.!?\n])\s+')
WORD_RE = re.compile(r"[\w\u0400-\u04FF]+", re.UNICODE)


def read_pdf(file, max_pages=5):
    try:
        with pdfplumber.open(file) as pdf:
            pages = min(max_pages, len(pdf.pages))
            return "\n".join((pdf.pages[i].extract_text() or "") for i in range(pages))
    except Exception:
        return ""


def tokenize(text):
    return [w.lower() for w in WORD_RE.findall(text)]


def summarize(text, max_chars=1000):
    if not text or not text.strip():
        return ""
    sents = SENT_RE.split(text.strip())
    toks = [t for t in tokenize(text) if len(t) > 2 and t not in K_STOP]
    freqs = Counter(toks)
    if not freqs:
        return ' '.join(sents[:3])[:max_chars]
    scored = []
    for s in sents:
        score = sum(freqs.get(w, 0) for w in tokenize(s))
        scored.append((score, s))
    scored.sort(reverse=True)
    out = []
    total = 0
    for _, s in scored:
        part = s.strip()
        if not part:
            continue
        if total + len(part) + 1 > max_chars:
            continue
        out.append(part)
        total += len(part) + 1
        if total >= max_chars:
            break
    return ' '.join(out)[:max_chars] if out else (sents[0][:max_chars] if sents else "")


def extract_terms(text, max_items=5):
    toks = tokenize(text)
    uni = Counter(w for w in toks if len(w) > 2 and w not in K_STOP)
    bi = Counter(' '.join((toks[i], toks[i + 1])) for i in range(len(toks) - 1)
                 if toks[i] not in K_STOP and toks[i + 1] not in K_STOP)
    tri = Counter(' '.join((toks[i], toks[i + 1], toks[i + 2])) for i in range(len(toks) - 2)
                  if toks[i] not in K_STOP and toks[i + 1] not in K_STOP and toks[i + 2] not in K_STOP)
    candidates = []
    candidates += [(cnt * 9, t) for t, cnt in tri.items()]
    candidates += [(cnt * 3, t) for t, cnt in bi.items()]
    candidates += [(cnt, t) for t, cnt in uni.items()]
    candidates.sort(reverse=True)
    seen = set()
    out = []
    for _, term in candidates:
        if term in seen:
            continue
        seen.add(term)
        out.append(term)
        if len(out) >= max_items:
            break
    return out


def find_definition(term, sents, full_text):
    pat = re.compile(r'\b' + re.escape(term) + r'\b\s*[\-:‚Äî‚Äì]\s*([^\n]+)', re.IGNORECASE)
    m = pat.search(full_text)
    if m:
        return m.group(1).strip()
    for i, s in enumerate(sents):
        if re.search(r'\b' + re.escape(term) + r'\b', s, re.IGNORECASE):
            # prefer clause after dash/colon
            parts = re.split(r'[\-:‚Äî‚Äì]', s)
            if len(parts) > 1 and parts[1].strip():
                return parts[1].strip()
            # else return short context
            start = max(0, i - 1)
            return ' '.join(sents[start:min(len(sents), i + 2)]).strip()
    return ""


def analyze(text, max_items=5):
    if not text or not text.strip():
        return {"error": "empty_text"}
    overview = summarize(text, max_chars=1200)
    sents = SENT_RE.split(text.strip())
    terms = extract_terms(text, max_items=max_items)
    defs = {}
    exps = {}
    for t in terms:
        d = find_definition(t, sents, text)
        defs[t] = d
        if d:
            exps[t] = summarize(d + ' ' + ' '.join(sents[max(0, 0):min(len(sents), 3)]), max_chars=500)
        else:
            ctx = ''
            for i, s in enumerate(sents):
                if re.search(r'\\b' + re.escape(t) + r'\\b', s, re.IGNORECASE):
                    start = max(0, i - 1)
                    ctx = ' '.join(sents[start:min(len(sents), i + 2)])
                    break
            exps[t] = summarize(ctx or t, max_chars=500)
    return {"overview": overview, "definitions": defs, "explanations": exps}


with st.sidebar:
    st.header("–î–æ–∫—É–º–µ–Ω—Ç –∂“Ø–∫—Ç”©”©")
    uploaded_file = st.file_uploader("PDF –∂“Ø–∫—Ç”©”© (–±–∏—Ä–∏–Ω—á–∏ 5 –±–µ—Ç –∫–æ–ª–¥–æ–Ω—É–ª–∞—Ç)", type="pdf")
    st.markdown("---")
    st.write("This is a demo prototype designed to showcase the app's main features. Outputs may be uninformative or incorrect on purpose because this version does not include a trained AI model yet.")
    st.markdown("---")

if uploaded_file:
    full_text = read_pdf(uploaded_file, max_pages=5)
    if not full_text.strip():
        st.warning("PDF—Ç–µ–Ω —Ç–µ–∫—Å—Ç –∞–ª—ã–Ω–≥–∞–Ω –∂–æ–∫. –ê—Ä –±–∏—Ä –±–µ—Ç—Ç–µ–Ω —Ç–µ–∫—Å—Ç –æ—Ä—Ç–æ–ª—É–ø –∂–∞—Ç–∫–∞–Ω—ã–Ω —Ç–µ–∫—à–µ—Ä–∏–ø –∫–∞–π—Ä–∞ –∂“Ø–∫—Ç”©“£“Ø–∑.")
    else:
        st.session_state['doc_text'] = full_text
        st.success(f"PDF—Ç–µ–Ω {len(full_text)} —Å–∏–º–≤–æ–ª –∂“Ø–∫—Ç”©–ª–¥“Ø.")

if 'doc_text' in st.session_state:
    with st.expander("–ê–ª—ã–Ω–≥–∞–Ω —Ç–µ–∫—Å—Ç—Ç–∏ –∞–ª–¥—ã–Ω –∞–ª–∞ –∫”©—Ä“Ø“Ø"):
        st.text_area("–ê–ª—ã–Ω–≥–∞–Ω —Ç–µ–∫—Å—Ç ( –±–∏—Ä–∏–Ω—á–∏ 20000 —Å–∏–º–≤–æ–ª )", value=st.session_state['doc_text'][:20000], height=220, key="preview_text", disabled=True)
        st.write(f"–ê–ª—ã–Ω–≥–∞–Ω —É–∑—É–Ω–¥—É–∫: {len(st.session_state['doc_text'])} —Å–∏–º–≤–æ–ª")

    st.subheader("–û–∫—É—É —Ç–∞–ª–¥–æ–æ—Å—É")
    left, right = st.columns([3, 1])
    with right:
        max_items = st.number_input("–ö”©—Ä—Å”©—Ç”© —Ç—É—Ä–≥–∞–Ω —Ç–µ—Ä–º–∏–Ω–¥–µ—Ä", min_value=1, max_value=20, value=5, step=1)
        run_analysis = st.button("–û–∫—É—É —Ç–∞–ª–¥–æ–æ—Å—É–Ω —Ç“Ø–∑“Ø“Ø")

    if run_analysis:
        st.session_state['run_analysis'] = True
        with st.spinner('–¢–∞–ª–¥–æ–æ –∂“Ø—Ä–≥“Ø–∑“Ø–ª“Ø“Ø–¥”©...'):
            res = analyze(st.session_state['doc_text'], max_items=max_items)
            st.session_state['analysis_result'] = res

    if 'analysis_result' in st.session_state:
        res = st.session_state['analysis_result']
        if not isinstance(res, dict) or 'error' in res:
            msg = res.get('message', '–ë–µ–ª–≥–∏—Å–∏–∑ –∫–∞—Ç–∞') if isinstance(res, dict) else '–ù–∞—Ç—ã–π–∂–∞ —Ç—É—É—Ä–∞ —ç–º–µ—Å —Ñ–æ—Ä–º–∞—Ç—Ç–∞'
            st.error(f"–¢–∞–ª–¥–æ–æ–¥–æ–Ω –∫–∞—Ç–∞ –∫–µ—Ç—Ç–∏: {msg}")
        else:
            st.markdown("### –ö—ã—Å–∫–∞—á–∞")
            overview_text = res.get('overview', '')
            st.write(overview_text)

            st.markdown("### –ú–∞–∞–Ω–∏–ª“Ø“Ø —Ç–µ—Ä–º–∏–Ω–¥–µ—Ä")
            definitions = res.get('definitions', {}) or {}
            explanations = res.get('explanations', {}) or {}
            if definitions:
                for term, d in definitions.items():
                    exp = explanations.get(term, '')
                    with st.expander(f"{term}"):
                        if exp: st.write(f"**–¢“Ø—à“Ø–Ω–¥“Ø—Ä–º”©:**\n{exp}")
                        if d: st.write(f"**–ê–Ω—ã–∫—Ç–∞–º–∞:**\n{d}")
                        if not d and not exp: st.write('–ë—É–ª —Ç–µ—Ä–º–∏–Ω “Ø—á“Ø–Ω –∫–æ—à—É–º—á–∞ –º–∞–∞–ª—ã–º–∞—Ç —Ç–∞–±—ã–ª–≥–∞–Ω –∂–æ–∫.')
            else:
                st.write('–ú–∞–∞–Ω–∏–ª“Ø“Ø —Ç–µ—Ä–º–∏–Ω–¥–µ—Ä —Ç–∞–±—ã–ª–≥–∞–Ω –∂–æ–∫.')

            if overview_text:
                st.markdown("### –ê—É–¥–∏–æ –æ–±–∑–æ—Ä")
                if st.button("–ê—É–¥–∏–æ–Ω—É –æ–π–Ω–æ—Ç—É—É"):
                    with st.spinner("–ê—É–¥–∏–æ —Ç“Ø–∑“Ø“Ø..."):
                        try:
                            import importlib
                            spec = importlib.util.find_spec('gtts')
                            if spec is None:
                                st.error("gTTS (text-to-speech) library not installed; install 'gTTS' to enable audio.")
                            else:
                                gtts = importlib.import_module('gtts')
                                gTTS = getattr(gtts, 'gTTS')
                                lang = os.getenv('TTS_LANG', 'ru')
                                text_for_audio = " ".join(overview_text.split()[:25])
                                tts = gTTS(text=text_for_audio, lang=lang)
                                audio_fp = io.BytesIO()
                                tts.write_to_fp(audio_fp)
                                audio_fp.seek(0)
                                st.audio(audio_fp, format='audio/mp3')
                        except Exception as e:
                            st.error(f"–ê—É–¥–∏–æ —Ç“Ø–∑“Ø“Ø–¥”© –∫–∞—Ç–∞ –∫–µ—Ç—Ç–∏: {e}")

            st.markdown("---")
            st.markdown("### üÉè –§–ª–µ—à-–∫–∞—Ä—Ç–∞–ª–∞—Ä")

            if 'flashcards' not in st.session_state:
                st.session_state.flashcards = []

            col1, col2 = st.columns([1, 3])
            with col1:
                if st.button("–§–ª–µ—à-–∫–∞—Ä—Ç–∞–ª–∞—Ä–¥—ã —Ç“Ø–∑“Ø“Ø"):
                    if definitions:
                        st.session_state.flashcards = list(definitions.items())
                        st.session_state.card_index = 0
                        st.session_state.card_revealed = False
                        st.rerun()
                    else:
                        st.warning("–§–ª–µ—à-–∫–∞—Ä—Ç–∞–ª–∞—Ä “Ø—á“Ø–Ω —Ç–µ—Ä–º–∏–Ω–¥–µ—Ä —Ç–∞–±—ã–ª–≥–∞–Ω –∂–æ–∫.")

            if st.session_state.flashcards:
                total_cards = len(st.session_state.flashcards)
                if 'card_index' not in st.session_state:
                    st.session_state.card_index = 0

                st.session_state.card_index %= total_cards
                term, definition = st.session_state.flashcards[st.session_state.card_index]

                nav_col1, nav_col2, nav_col3 = st.columns([1, 1, 1])
                with nav_col1:
                    if st.button("‚óÄÔ∏è –ê—Ä—Ç–∫–∞"):
                        st.session_state.card_index -= 1
                        st.session_state.card_revealed = False
                        st.rerun()
                with nav_col3:
                    if st.button("–∞–ª–¥—ã–≥–∞ ‚ñ∂Ô∏è"):
                        st.session_state.card_index += 1
                        st.session_state.card_revealed = False
                        st.rerun()

                with st.container():
                    st.markdown(f"""
                    <div style="border: 1px solid #333; border-radius: 10px; padding: 25px; text-align: center; min-height: 200px; cursor: pointer;" onclick="this.querySelector('button').click();">
                        <h4>{term}</h4>
                    """, unsafe_allow_html=True)

                    if st.session_state.get('card_revealed', False):
                        st.write(definition or "–ê–Ω—ã–∫—Ç–∞–º–∞ —Ç–∞–±—ã–ª–≥–∞–Ω –∂–æ–∫.")
                        if st.button("–ñ–∞–±—É—É", key=f"hide_{st.session_state.card_index}"):
                            st.session_state.card_revealed = False
                            st.rerun()
                    else:
                        if st.button("–ê—á—É—É", key=f"reveal_{st.session_state.card_index}", help="Click to reveal definition"):
                            st.session_state.card_revealed = True
                            st.rerun()

                    st.caption(f"–ö–∞—Ä—Ç–∞ {st.session_state.card_index + 1}/{total_cards}")
                    st.markdown("</div>", unsafe_allow_html=True)

    st.markdown("---")
    st.subheader("üí¨ –ß–∞—Ç")

    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("–î–æ–∫—É–º–µ–Ω—Ç –±–æ—é–Ω—á–∞ —Å—É—Ä–æ–æ“£—É–∑–¥—É –±–µ—Ä–∏“£–∏–∑"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = "–ë—É–ª –¥–µ–º–æ-—á–∞—Ç. –¢–æ–ª—É–∫ –≤–µ—Ä—Å–∏—è–¥–∞ –º–æ–¥–µ–ª—å –¥–æ–∫—É–º–µ–Ω—Ç—Ç–∏–Ω –º–∞–∑–º—É–Ω—É–Ω–∞ –∂–∞—Ä–∞—à–∞ –∂–æ–æ–ø –±–µ—Ä–µ—Ç."

            message_placeholder.markdown(full_response)
        st.session_state.messages.append({"role": "assistant", "content": full_response})

else:
    st.info("–ë–∞—à—Ç–æ–æ “Ø—á“Ø–Ω —Å–æ–ª –∂–∞–∫—Ç–∞–Ω PDF –∂“Ø–∫—Ç”©“£“Ø–∑.")
